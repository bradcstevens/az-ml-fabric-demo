# Product Requirements Document (PRD)

## ğŸ¯ Predictive Analytics MVP

> **Project Type:** Machine Learning MVP
> **Industry:** Manufacturing/Operations
> **Technology Stack:** Microsoft Fabric, Azure Machine Learning, Power BI

---

## ğŸ“‹ Table of Contents

- [1. Overview](#1-overview)
- [2. Goals](#2-goals)
- [3. Functional Requirements](#3-functional-requirements)
- [4. Non-Functional Requirements](#4-non-functional-requirements)
- [5. Architecture Components](#5-architecture-components)
- [6. Architecture Diagram](#6-architecture-diagram)
- [7. Sequence Diagram](#7-sequence-diagram)

---

## 1. Overview

This MVP demonstrates a **hybrid architecture** for predictive analytics using custom machine learning models. The solution integrates:

- **Microsoft Fabric** for data storage and reporting
- **Azure Machine Learning** for model training and real-time inference
- **Dual scoring capabilities** supporting both batch and real-time predictions
- **Legacy integration** via REST API without dependency on lookup tables

### Key Value Propositions
âœ… Real-time predictions for operational decision making
âœ… Automated batch scoring for reporting and analytics
âœ… Seamless integration with existing legacy systems
âœ… Enterprise-grade security and scalability
âœ… **One-command deployment** using Azure Developer CLI (azd)
âœ… **Infrastructure as Code** with maintainable Bicep templates

---

## 2. Goals

### Primary Objectives
- ğŸ¯ **Showcase real-time scoring** via Azure ML Online Endpoints
- ğŸ”„ **Demonstrate batch scoring pipeline** using Azure ML Pipelines
- ğŸ“Š **Maintain data prep and reporting** in Microsoft Fabric
- ğŸ”Œ **Enable legacy app integration** without relying on lookup tables
- âœ… **Validate performance, scalability, and integration patterns**

---

## 3. Functional Requirements

| ğŸ”§ **Feature** | ğŸ“ **Description** | ğŸ—ï¸ **Implementation** |
|----------------|--------------------|-----------------------|
| **Data Ingestion** | Operational data collection and storage | Fabric OneLake with automated ingestion |
| **Data Preparation** | Feature engineering and data transformation | Fabric Notebooks with PySpark |
| **Model Training** | Custom ML model development and training | Azure ML with Random Forest & Neural Networks |
| **Batch Scoring** | Automated nightly prediction generation | Azure ML Pipelines with scheduled execution |
| **Real-Time Scoring** | On-demand prediction API | Azure ML Online Endpoints (REST API) |
| **Operational Reporting** | Business intelligence and dashboards | Power BI consuming OneLake predictions |

---

## 4. Non-Functional Requirements

### Performance & SLA Requirements
| ğŸ“ **Metric** | ğŸ¯ **Target** | ğŸ“‹ **Description** |
|---------------|---------------|-------------------|
| **Latency** | `< 1 second` | Real-time scoring response time |
| **Batch SLA** | `< 30 minutes` | Nightly scoring completion window |
| **Availability** | `99.9%` | System uptime requirement |
| **Throughput** | `1000 req/min` | Peak real-time scoring capacity |

### Security & Compliance
- ğŸ” **Authentication**: Azure Active Directory (AAD) based access control
- ğŸŒ **Network Security**: Private endpoints and VNet integration
- ğŸ”‘ **Identity Management**: Managed identities for service-to-service authentication
- ğŸ“Š **Monitoring**: Azure Monitor and Application Insights for observability
- âš–ï¸ **Compliance**: Enterprise data governance standards

### Scalability & Operations
- ğŸ“ˆ **Auto-scaling**: Dynamic compute clusters for training and inference
- ğŸ”„ **Model Versioning**: Automated model lifecycle management
- ğŸ“± **Monitoring**: Comprehensive logging and alerting
- ğŸš€ **Deployment**: Blue-green deployment strategies

---

## 5. Architecture Components

| ğŸ—ï¸ **Component** | â˜ï¸ **Azure Service** | ğŸ¯ **Primary Role** | ğŸ“ **Notes** |
|------------------|---------------------|-------------------|-------------|
| **Data Lake** | Fabric OneLake | Raw and processed data storage | Unified storage layer |
| **Data Preparation** | Fabric Notebooks | Feature engineering pipeline | PySpark-based processing |
| **Model Training** | Azure ML Compute Cluster | GPU-enabled model training | Scalable compute resources |
| **Model Registry** | Azure ML Model Registry | Versioned model artifacts | MLOps integration |
| **Batch Scoring** | Azure ML Pipelines | Scheduled prediction jobs | Automated execution |
| **Real-Time Scoring** | Azure ML Online Endpoint | REST API for predictions | Low-latency inference |
| **Business Intelligence** | Power BI Premium | Interactive dashboards | Real-time data visualization |
| **Monitoring** | Azure Monitor + App Insights | System observability | Performance tracking |
| **Security** | Azure Key Vault + RBAC | Secrets and access management | Enterprise security |

---

## 6. Architecture Diagram

### System Architecture Flow

```mermaid
flowchart TD
    %% Data Layer
    A["ğŸ¢ Fabric OneLake<br/>(Data Lakehouse)"] --> B["ğŸ““ Fabric Notebooks<br/>(Data Prep & Feature Engineering)"]

    %% Training Pipeline
    B --> C["ğŸ–¥ï¸ Azure ML Compute Cluster<br/>(GPU-Enabled Training)"]
    C --> D["ğŸ§  Model Training<br/>(Python Notebooks)"]
    D --> E["ğŸ“¦ Azure ML Model Registry<br/>(Versioned Models)"]

    %% Scoring Pipelines
    E --> F["â° Azure ML Batch Scoring<br/>(Nightly Pipeline)"]
    F --> G["ğŸ“Š Batch Predictions<br/>(Stored in OneLake)"]
    E --> H["ğŸš€ Azure ML Online Endpoint<br/>(Real-time API)"]

    %% Consumer Applications
    I["ğŸ­ Legacy Operational Apps"] --> H
    G --> J["ğŸ“ˆ Power BI Reports<br/>(Business Intelligence)"]

    %% Monitoring & Observability
    subgraph "ğŸ” Monitoring & Observability"
        K["ğŸ“Š Azure Monitor<br/>(Infrastructure)"]
        L["ğŸ” Application Insights<br/>(Application Performance)"]
    end

    %% Monitoring Connections
    H --> L
    C --> K
    F --> L

    %% Styling
    classDef dataLayer fill:#e1f5fe
    classDef mlLayer fill:#f3e5f5
    classDef appLayer fill:#e8f5e8
    classDef monitorLayer fill:#fff3e0

    class A,G dataLayer
    class B,C,D,E,F,H mlLayer
    class I,J appLayer
    class K,L monitorLayer
```

---

## 7. Sequence Diagram

### End-to-End Data Flow and Interactions

```mermaid
sequenceDiagram
    participant ED as ğŸ“Š Operational Data<br/>(Fabric OneLake)
    participant DP as ğŸ““ Data Prep<br/>(Fabric Notebooks)
    participant ML as ğŸ§  Model Training<br/>(Azure ML)
    participant MR as ğŸ“¦ Model Registry<br/>(Azure ML)
    participant BS as â° Batch Scoring<br/>(Azure ML Pipeline)
    participant RT as ğŸš€ Real-Time API<br/>(Online Endpoint)
    participant LA as ğŸ­ Legacy App
    participant PB as ğŸ“ˆ Power BI<br/>(Reporting)

    Note over ED,PB: ğŸ”„ Training & Batch Scoring Workflow
    ED->>+DP: 1. Ingest raw operational data
    DP->>+ML: 2. Send prepared features for training
    ML->>+MR: 3. Register trained model (v1.0)
    MR->>+BS: 4. Trigger nightly batch scoring
    BS->>+ED: 5. Store batch predictions in OneLake
    ED->>+PB: 6. Load predictions for visualization

    Note over LA,RT: âš¡ Real-Time Scoring Workflow
    LA->>+RT: 7. Send scoring request (REST API)
    RT->>+MR: 8. Load latest model version
    MR-->>-RT: 9. Return model artifacts
    RT-->>-LA: 10. Return predictive outcome

    Note over ED,PB: ğŸ”„ Continuous Operation
    Note right of BS: Runs nightly at 2:00 AM
    Note right of RT: < 1 second response time
    Note right of PB: Real-time dashboard updates
```

---

## ğŸ¯ Next Steps

### Implementation Phases

1. **Phase 1: Data Foundation**
   - Set up Fabric workspace and OneLake
   - **Generate synthetic operational data** for demo purposes
     - Create realistic manufacturing/operational datasets
     - Include time-series data with seasonal patterns
     - Generate historical performance metrics and equipment telemetry
     - Add controlled anomalies for predictive model validation
   - Implement data ingestion pipelines
   - Create initial data preparation notebooks
   - **Validate synthetic data quality** and statistical properties

2. **Phase 2: Model Development**
   - Develop and train ML models in Azure ML
   - Implement model registry and versioning
   - Establish MLOps practices

3. **Phase 3: Azure Developer CLI (azd) Deployment Infrastructure**
   - **Initialize azd project structure**
     - Create `azure.yaml` configuration file
     - Set up project metadata and service definitions
     - Configure environment-specific parameters
   - **Create Azure Bicep infrastructure templates**
     - Design modular Bicep files for each Azure service
     - Implement Azure ML workspace and compute resources
     - Configure Microsoft Fabric workspace and OneLake
     - Set up Azure Monitor and Application Insights
     - Define network security and private endpoints
   - **Develop Azure CLI deployment scripts**
     - Create pre-deployment validation scripts
     - Implement post-deployment configuration scripts
     - Add environment setup and resource verification
   - **Configure azd deployment workflows**
     - Set up multi-environment support (dev, staging, prod)
     - Implement infrastructure provisioning via `azd provision`
     - Configure application deployment via `azd deploy`
     - Test complete deployment with `azd up`
   - **Create deployment documentation**
     - Write step-by-step azd deployment guide
     - Document prerequisites and Azure subscription setup
     - Include troubleshooting and common deployment issues
     - Provide environment-specific configuration examples

4. **Phase 4: Scoring Infrastructure**
   - Deploy batch scoring pipelines
   - Set up real-time endpoint
   - Implement monitoring and alerting

5. **Phase 5: Integration & Testing**
   - Integrate with legacy applications
   - Create Power BI dashboards
   - Conduct end-to-end testing

### Success Criteria

âœ… **Real-time predictions** delivered under 1-second latency
âœ… **Batch scoring** completed within 30-minute SLA
âœ… **Legacy integration** functional without code changes
âœ… **Business dashboards** displaying accurate predictions
âœ… **System monitoring** providing full observability
âœ… **One-command deployment** via `azd up` from clean Azure subscription
âœ… **Multi-environment support** with dev, staging, and production configurations
âœ… **Infrastructure as Code** with version-controlled Bicep templates

---

*Document Version: 1.0 | Last Updated: $(date)