{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic Data Generation Notebook\n",
        "\n",
        "This notebook demonstrates how to generate synthetic datasets for the Azure ML Fabric Demo predictive analytics MVP.\n",
        "\n",
        "## Objectives\n",
        "- Generate realistic manufacturing production data\n",
        "- Create time-series data with seasonal patterns\n",
        "- Simulate equipment telemetry with controlled variations\n",
        "- Inject controlled anomalies for model validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Manufacturing Production Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_manufacturing_data(num_records=1000, start_date='2024-01-01'):\n",
        "    \"\"\"Generate synthetic manufacturing production data\"\"\"\n",
        "    \n",
        "    data = []\n",
        "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
        "    \n",
        "    production_lines = ['LINE_A', 'LINE_B', 'LINE_C', 'LINE_D']\n",
        "    operators = [f'OP{i:03d}' for i in range(1, 21)]  # 20 operators\n",
        "    shifts = ['DAY', 'NIGHT', 'EVENING']\n",
        "    \n",
        "    for i in range(num_records):\n",
        "        # Time progression (hourly data)\n",
        "        timestamp = start + timedelta(hours=i)\n",
        "        \n",
        "        # Line-specific base performance\n",
        "        line = random.choice(production_lines)\n",
        "        base_output = {\n",
        "            'LINE_A': 1200,\n",
        "            'LINE_B': 1000,\n",
        "            'LINE_C': 1350,\n",
        "            'LINE_D': 900\n",
        "        }[line]\n",
        "        \n",
        "        # Shift and time-based variations\n",
        "        shift = shifts[timestamp.hour // 8]  # 8-hour shifts\n",
        "        shift_multiplier = {'DAY': 1.0, 'EVENING': 0.95, 'NIGHT': 0.9}[shift]\n",
        "        \n",
        "        # Add random variations and trends\n",
        "        output_quantity = int(base_output * shift_multiplier * (0.8 + 0.4 * np.random.random()))\n",
        "        \n",
        "        # Correlated defect rate (higher output often means higher defects)\n",
        "        base_defect_rate = 0.02\n",
        "        if output_quantity > base_output * 1.1:\n",
        "            defect_rate = base_defect_rate * (1 + np.random.exponential(0.5))\n",
        "        else:\n",
        "            defect_rate = base_defect_rate * (0.5 + 0.5 * np.random.random())\n",
        "        defect_rate = min(defect_rate, 0.1)  # Cap at 10%\n",
        "        \n",
        "        # Machine efficiency (inversely related to defect rate)\n",
        "        base_efficiency = 0.92\n",
        "        efficiency_factor = 1 - (defect_rate - base_defect_rate) * 2\n",
        "        machine_efficiency = base_efficiency * efficiency_factor * (0.9 + 0.2 * np.random.random())\n",
        "        machine_efficiency = max(0.75, min(1.0, machine_efficiency))\n",
        "        \n",
        "        data.append({\n",
        "            'timestamp': timestamp.isoformat() + 'Z',\n",
        "            'production_line': line,\n",
        "            'output_quantity': output_quantity,\n",
        "            'defect_rate': round(defect_rate, 4),\n",
        "            'machine_efficiency': round(machine_efficiency, 3),\n",
        "            'operator_id': random.choice(operators),\n",
        "            'shift': shift\n",
        "        })\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Generate manufacturing data\n",
        "manufacturing_data = generate_manufacturing_data(500)\n",
        "print(f\"Generated {len(manufacturing_data)} manufacturing records\")\n",
        "print(\"Sample records:\")\n",
        "for i in range(3):\n",
        "    print(json.dumps(manufacturing_data[i], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Time-Series Data with Seasonal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_seasonal_timeseries(days=400, start_date='2024-01-01'):\n",
        "    \"\"\"Generate time-series data with clear seasonal patterns\"\"\"\n",
        "    \n",
        "    data = []\n",
        "    start = datetime.strptime(start_date, '%Y-%m-%d')\n",
        "    \n",
        "    for i in range(days):\n",
        "        date = start + timedelta(days=i)\n",
        "        day_of_year = date.timetuple().tm_yday\n",
        "        \n",
        "        # Multiple seasonal components\n",
        "        yearly_cycle = 20 * np.sin(2 * np.pi * day_of_year / 365)  # Annual cycle\n",
        "        weekly_cycle = 5 * np.sin(2 * np.pi * (i % 7) / 7)  # Weekly cycle\n",
        "        \n",
        "        # Combine seasonal components\n",
        "        seasonal_component = yearly_cycle + weekly_cycle\n",
        "        \n",
        "        # Trend component\n",
        "        trend = 100 + (i * 0.05) + (0.001 * i**1.1)  # Slight acceleration\n",
        "        \n",
        "        # Noise component\n",
        "        noise = np.random.normal(0, 3)\n",
        "        \n",
        "        # Combined value\n",
        "        value = trend + seasonal_component + noise\n",
        "        \n",
        "        data.append({\n",
        "            'date': date.strftime('%Y-%m-%d'),\n",
        "            'value': round(value, 2),\n",
        "            'seasonal_component': round(seasonal_component, 2),\n",
        "            'trend': round(trend, 2),\n",
        "            'day_of_year': day_of_year\n",
        "        })\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Generate seasonal time-series data\n",
        "timeseries_data = generate_seasonal_timeseries(450)\n",
        "print(f\"Generated {len(timeseries_data)} time-series records\")\n",
        "\n",
        "# Visualize seasonal pattern\n",
        "df_temp = pd.DataFrame(timeseries_data[:100])\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(df_temp['date'], df_temp['value'], label='Total Value')\n",
        "plt.plot(df_temp['date'], df_temp['seasonal_component'], label='Seasonal Component')\n",
        "plt.title('Time-series with Seasonal Pattern (First 100 days)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Equipment Telemetry Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_equipment_telemetry(num_records=200, equipment_types=None):\n",
        "    \"\"\"Generate realistic equipment telemetry data\"\"\"\n",
        "    \n",
        "    if equipment_types is None:\n",
        "        equipment_types = {\n",
        "            'PUMP': {'temp_range': (70, 85), 'vib_range': (1.5, 3.0), 'press_range': (10, 20)},\n",
        "            'MOTOR': {'temp_range': (65, 80), 'vib_range': (1.0, 2.5), 'press_range': (5, 15)},\n",
        "            'COMPRESSOR': {'temp_range': (75, 90), 'vib_range': (2.0, 4.0), 'press_range': (20, 35)},\n",
        "            'GENERATOR': {'temp_range': (60, 75), 'vib_range': (1.2, 2.8), 'press_range': (8, 18)}\n",
        "        }\n",
        "    \n",
        "    data = []\n",
        "    start_time = datetime.now() - timedelta(days=7)  # Last week's data\n",
        "    \n",
        "    equipment_instances = []\n",
        "    for eq_type, params in equipment_types.items():\n",
        "        for i in range(1, 4):  # 3 instances of each type\n",
        "            equipment_instances.append((f'{eq_type}_{i:03d}', params))\n",
        "    \n",
        "    for i in range(num_records):\n",
        "        # Select random equipment\n",
        "        equipment_id, params = random.choice(equipment_instances)\n",
        "        \n",
        "        # Time progression (15-minute intervals)\n",
        "        timestamp = start_time + timedelta(minutes=15 * i)\n",
        "        \n",
        "        # Generate base readings within normal ranges\n",
        "        temp_min, temp_max = params['temp_range']\n",
        "        vib_min, vib_max = params['vib_range']\n",
        "        press_min, press_max = params['press_range']\n",
        "        \n",
        "        temperature = np.random.uniform(temp_min, temp_max)\n",
        "        vibration = np.random.uniform(vib_min, vib_max)\n",
        "        pressure = np.random.uniform(press_min, press_max)\n",
        "        \n",
        "        # Add some correlation between metrics\n",
        "        if temperature > (temp_min + temp_max) / 2:\n",
        "            vibration *= 1.2  # Higher temp = more vibration\n",
        "        \n",
        "        # Determine status based on readings\n",
        "        status = 'NORMAL'\n",
        "        if temperature > temp_max * 0.9 or vibration > vib_max * 0.9:\n",
        "            status = 'WARNING'\n",
        "        if temperature > temp_max or vibration > vib_max:\n",
        "            status = 'CRITICAL'\n",
        "        \n",
        "        # Flow rate (only for pumps and compressors)\n",
        "        if 'PUMP' in equipment_id or 'COMPRESSOR' in equipment_id:\n",
        "            flow_rate = np.random.uniform(100, 250)\n",
        "        else:\n",
        "            flow_rate = 0\n",
        "        \n",
        "        # Runtime hours (cumulative)\n",
        "        base_runtime = random.randint(500, 3000)\n",
        "        runtime_hours = base_runtime + (i * 0.25)  # 15 minutes = 0.25 hours\n",
        "        \n",
        "        data.append({\n",
        "            'equipment_id': equipment_id,\n",
        "            'timestamp': timestamp.isoformat() + 'Z',\n",
        "            'temperature': round(temperature, 1),\n",
        "            'vibration': round(vibration, 1),\n",
        "            'pressure': round(pressure, 1),\n",
        "            'flow_rate': round(flow_rate, 1),\n",
        "            'status': status,\n",
        "            'runtime_hours': round(runtime_hours, 2)\n",
        "        })\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Generate equipment telemetry data\n",
        "telemetry_data = generate_equipment_telemetry(150)\n",
        "print(f\"Generated {len(telemetry_data)} telemetry records\")\n",
        "\n",
        "# Show equipment distribution\n",
        "equipment_ids = [record['equipment_id'] for record in telemetry_data]\n",
        "unique_equipment = list(set(equipment_ids))\n",
        "print(f\"Unique equipment: {len(unique_equipment)}\")\n",
        "print(f\"Equipment types: {sorted(unique_equipment)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Controlled Anomaly Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_controlled_anomalies(num_anomalies=50, num_normal=30):\n",
        "    \"\"\"Generate controlled anomalies for model validation\"\"\"\n",
        "    \n",
        "    data = []\n",
        "    start_time = datetime.now() - timedelta(days=3)\n",
        "    equipment_ids = ['PUMP_001', 'MOTOR_002', 'COMPRESSOR_003', 'GENERATOR_004']\n",
        "    \n",
        "    anomaly_types = [\n",
        "        'TEMPERATURE_SPIKE',\n",
        "        'VIBRATION_ANOMALY', \n",
        "        'PRESSURE_DROP',\n",
        "        'EFFICIENCY_DROP',\n",
        "        'FLOW_IRREGULARITY'\n",
        "    ]\n",
        "    \n",
        "    severity_levels = ['LOW', 'MEDIUM', 'HIGH']\n",
        "    \n",
        "    # Generate anomalies\n",
        "    for i in range(num_anomalies):\n",
        "        timestamp = start_time + timedelta(minutes=random.randint(0, 4320))  # 3 days\n",
        "        equipment_id = random.choice(equipment_ids)\n",
        "        anomaly_type = random.choice(anomaly_types)\n",
        "        severity = random.choice(severity_levels)\n",
        "        \n",
        "        # Generate anomalous values based on type\n",
        "        if anomaly_type == 'TEMPERATURE_SPIKE':\n",
        "            value = random.uniform(90, 120)  # High temperature\n",
        "            threshold = 85.0\n",
        "        elif anomaly_type == 'VIBRATION_ANOMALY':\n",
        "            value = random.uniform(4.5, 8.0)  # High vibration\n",
        "            threshold = 4.0\n",
        "        elif anomaly_type == 'PRESSURE_DROP':\n",
        "            value = random.uniform(2, 8)  # Low pressure\n",
        "            threshold = 10.0\n",
        "        elif anomaly_type == 'EFFICIENCY_DROP':\n",
        "            value = random.uniform(0.3, 0.7)  # Low efficiency\n",
        "            threshold = 0.85\n",
        "        else:  # FLOW_IRREGULARITY\n",
        "            value = random.uniform(50, 80)  # Low flow\n",
        "            threshold = 100.0\n",
        "        \n",
        "        # Adjust severity\n",
        "        if severity == 'HIGH':\n",
        "            if anomaly_type in ['TEMPERATURE_SPIKE', 'VIBRATION_ANOMALY']:\n",
        "                value *= 1.3\n",
        "            else:\n",
        "                value *= 0.7\n",
        "        elif severity == 'LOW':\n",
        "            if anomaly_type in ['TEMPERATURE_SPIKE', 'VIBRATION_ANOMALY']:\n",
        "                value *= 0.9\n",
        "            else:\n",
        "                value *= 0.9\n",
        "        \n",
        "        data.append({\n",
        "            'timestamp': timestamp.isoformat() + 'Z',\n",
        "            'equipment_id': equipment_id,\n",
        "            'anomaly_type': anomaly_type,\n",
        "            'severity': severity,\n",
        "            'is_anomaly': True,\n",
        "            'value': round(value, 2),\n",
        "            'threshold': threshold,\n",
        "            'description': f'{anomaly_type.replace(\"_\", \" \").title()} detected with {severity.lower()} severity'\n",
        "        })\n",
        "    \n",
        "    # Generate normal readings\n",
        "    for i in range(num_normal):\n",
        "        timestamp = start_time + timedelta(minutes=random.randint(0, 4320))\n",
        "        equipment_id = random.choice(equipment_ids)\n",
        "        \n",
        "        # Normal operating values\n",
        "        value = random.uniform(70, 85)  # Normal range\n",
        "        threshold = 85.0\n",
        "        \n",
        "        data.append({\n",
        "            'timestamp': timestamp.isoformat() + 'Z',\n",
        "            'equipment_id': equipment_id,\n",
        "            'anomaly_type': 'NORMAL_OPERATION',\n",
        "            'severity': 'NONE',\n",
        "            'is_anomaly': False,\n",
        "            'value': round(value, 2),\n",
        "            'threshold': threshold,\n",
        "            'description': 'Equipment operating within normal parameters'\n",
        "        })\n",
        "    \n",
        "    # Sort by timestamp\n",
        "    data.sort(key=lambda x: x['timestamp'])\n",
        "    return data\n",
        "\n",
        "# Generate controlled anomalies\n",
        "anomaly_data = generate_controlled_anomalies(40, 20)\n",
        "print(f\"Generated {len(anomaly_data)} anomaly records\")\n",
        "\n",
        "# Show distribution\n",
        "anomaly_count = sum(1 for record in anomaly_data if record['is_anomaly'])\n",
        "normal_count = len(anomaly_data) - anomaly_count\n",
        "print(f\"Anomalies: {anomaly_count}, Normal: {normal_count}\")\n",
        "\n",
        "# Show severity distribution\n",
        "severity_dist = {}\n",
        "for record in anomaly_data:\n",
        "    sev = record['severity']\n",
        "    severity_dist[sev] = severity_dist.get(sev, 0) + 1\n",
        "print(f\"Severity distribution: {severity_dist}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Generated Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all generated datasets\n",
        "import os\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs('../data/synthetic', exist_ok=True)\n",
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "\n",
        "# Save synthetic data\n",
        "with open('../data/synthetic/manufacturing_data.json', 'w') as f:\n",
        "    json.dump(manufacturing_data, f, indent=2)\n",
        "\n",
        "with open('../data/synthetic/timeseries_seasonal.json', 'w') as f:\n",
        "    json.dump(timeseries_data, f, indent=2)\n",
        "\n",
        "with open('../data/synthetic/equipment_telemetry.json', 'w') as f:\n",
        "    json.dump(telemetry_data, f, indent=2)\n",
        "\n",
        "with open('../data/synthetic/anomalies_controlled.json', 'w') as f:\n",
        "    json.dump(anomaly_data, f, indent=2)\n",
        "\n",
        "print(\"All synthetic datasets saved successfully!\")\n",
        "print(\"Files created:\")\n",
        "print(\"- manufacturing_data.json\")\n",
        "print(\"- timeseries_seasonal.json\")\n",
        "print(\"- equipment_telemetry.json\")\n",
        "print(\"- anomalies_controlled.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Summary and Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive data summary\n",
        "print(\"=== SYNTHETIC DATA GENERATION SUMMARY ===\")\n",
        "print(f\"\\n1. Manufacturing Data:\")\n",
        "print(f\"   - Records: {len(manufacturing_data)}\")\n",
        "print(f\"   - Date range: {manufacturing_data[0]['timestamp']} to {manufacturing_data[-1]['timestamp']}\")\n",
        "print(f\"   - Production lines: {len(set(r['production_line'] for r in manufacturing_data))}\")\n",
        "\n",
        "print(f\"\\n2. Time-series Data:\")\n",
        "print(f\"   - Records: {len(timeseries_data)}\")\n",
        "print(f\"   - Date range: {timeseries_data[0]['date']} to {timeseries_data[-1]['date']}\")\n",
        "print(f\"   - Seasonal range: {min(r['seasonal_component'] for r in timeseries_data):.1f} to {max(r['seasonal_component'] for r in timeseries_data):.1f}\")\n",
        "\n",
        "print(f\"\\n3. Equipment Telemetry:\")\n",
        "print(f\"   - Records: {len(telemetry_data)}\")\n",
        "print(f\"   - Unique equipment: {len(set(r['equipment_id'] for r in telemetry_data))}\")\n",
        "status_dist = {}\n",
        "for r in telemetry_data:\n",
        "    status_dist[r['status']] = status_dist.get(r['status'], 0) + 1\n",
        "print(f\"   - Status distribution: {status_dist}\")\n",
        "\n",
        "print(f\"\\n4. Controlled Anomalies:\")\n",
        "print(f\"   - Total records: {len(anomaly_data)}\")\n",
        "print(f\"   - Anomalies: {sum(1 for r in anomaly_data if r['is_anomaly'])}\")\n",
        "print(f\"   - Normal: {sum(1 for r in anomaly_data if not r['is_anomaly'])}\")\n",
        "\n",
        "print(\"\\n=== DATA READY FOR ML PIPELINE ===\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}